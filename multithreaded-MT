  多线程编程对于具有如下特点的编程任务而言是非常理想的： 
      本质上是异步的；
      需要多个并发活动；
      每个活动的处理顺序可能是不确定的，或者说是随机的、不可预测的。
  这种编程任务可以被组织或划分成多个执行流，其中每个执行流都有一个指定要完成的任务。
  根据应用的不同，这些子任务可能需要计算出中间结果，然后合并为最终的输出结果。
  
  如果不是用多线程，要实现这种编程任务就需要位串行程序使用一个或多个计时器，并实现一个多路复用方案。
  
  一个串行程序需要从每个I/O终端通道来检查用户的输入；然而，有一点非常重要，程序在读取I/O终端通道时不能阻塞，因为用户输入的到达时间是不确定的，
  并且阻塞会妨碍其它I/O通道的处理。串行程序必须使用非阻塞I/O或用有计时器的阻塞I/O（以保证阻塞只是暂时的）。
  
  由于串行程序只有唯一的执行线程，因此它必须兼顾需要执行的多个任务，确保其中的某个任务不会占用过多时间，并对用户的响应时间进行合理的分配。
  这种任务类型的串行程序的使用，往往造成非常复杂的控制流，难以理解和维护。
  
  编程任务可以规划成几个执行特定函数的线程：
      UserRequesrtThread： 负责读取客户端输入，该输入可能来自I/O通道。程序将创建多个线程，每个客户端一个，客户端的请求将会被放入队列中。
      RequestProcessor： 该线程负责从队列中获取请求并进行处理，为第3个线程提供输出。
      ReplyThread： 负责向用户输出，将结果传回用户（如果是网络应用），或者把数据写道本地文件或数据库中。
      
      
  进程
  计算机程序只是存储在磁盘上的可执行二进制（或其他类型）文件。只有把他们加载到内存中并被操作系统使用，才拥有其生命期。
  进程（有时称为重量级进程）则是一个执行中的程序。每个进程都拥有自己的地址空间、内存、数据栈以及其他用于跟踪执行的辅助数据。
  操作系统管理器上所有进程的执行，并为这些进程合理的分配时间。进程也可以通过派生（fork或spawn）新的进程来执行其他任务，不过因为每个新进程
  都拥有自己的内存和数据栈等，所以只能采用进程间通信（IPC）的方式共享信息。
  
  
  线程
  线程（有时候成为轻量级进程）与进程类似，不过他们是在同一个进程下执行的，并共享相同的上下文。可以将他们认为是在一个主进程或“主线程”中并行运行的一些
  “迷你进程”。
  
  线程包括开始、执行顺序和结束三部分。他有一个指令指针，用于记录当时运行的上下文。当其他线程运行时，它可以被抢占（中断）和临时挂起（也成为睡眠）——
  ——这种做法叫作让步（yielding）。
  
  一个进程中的各个线程与主线程共享同一片数据空间，因此相比于独立的进程而言，线程间的信息共享和通信更加容易。
  线程一般是以并发方式执行的，正是由于这种并行和数据共享机制，使得多任务间的协作成为可能。在单核CPU系统中，因为真正的并发是不可能的，
  所以线程的执行实际是这样规划的： 每个线程运行一小会儿，然后让步给其它线程（再次排队等待更多的CPU时间）。在整个进程的执行过程中，
  每个线程执行他自己特定的任务，在必要时和其它线程进行结果通信。
  
  如果两个或多个线程访问同一片数据，由于数据访问顺序不同，可能导致结果不一致。这种情况通常称为静态条件（race condition）。幸运的是，
  大多数线程库都有一些同步原语，以允许线程管理器控制执行和访问。
  
  另一个需要注意的问题是，线程无法给予公平的执行时间。这是因为一些函数会在完成前保持阻塞状态，如果没有专门为多线程情况进行修改，会导致CPU的时间
  分配向这些贪婪的函数倾斜。
  
  
  全局解释器锁
  python代码块的执行是由python虚拟机（又名解释其主循环）进行控制的。python在设计时是这样考虑的，在主循环中同时只能由一个控制线程在执行，
  就像单核CPU系统中的多进程一样。内存中可以有许多程序，但是在任意给定时刻只能有一个程序在运行。同理，尽管Python解释器中可以运行多个线程，
  但在任意给定时刻只有一个线程会被解释器执行。
  
  对python虚拟机的访问是由全局解释器锁（GIL）控制的。这个锁就是用来保证同时只能有一个线程运行的。在多线程环境中，
  python虚拟机将按照下面所述的方式执行：
      1. 设置GIL
      2. 切换进一个线程去执行
      3. 执行下面的操作之一：
              a. 指定数量的字节码指令
              b. 线程主动让出控制权（可以调用time.sleep(0)来完成）
      4. 把线程设置回睡眠状态（切换出线程）
      5. 解锁GIL
      6. 重复上述步骤
      
  当调用外部代码（即，任意C/C++扩展的内置函数）时，GIL会保持锁定，直至函数执行结束（因为在这期间没有python字节码计数）。
  编写扩展函数的程序员有能力解锁GIL，然而，作为python开发者，你并不需要担心python代码会在这些情况下被锁住。
  
  对于任意面向I/O的python例程（调用了内置的操作系统C代码的那种），GIL会在I/O调用前被释放，以允许其他线程在I/O执行的时候运行。
  而对于那些没有太多I/O操作的代码而言，更倾向于在该线程整个时间片内始终占有处理器（和GIL）。
  换句话说就是，I/O密集型的python程序要比计算密集型的代码能够更好地利用多线程环境。
  
  如果对源代码、解释器主循环和GIL感兴趣，可以看看Python/ceval.c文件
  
  当一个线程完成函数的执行时，他就会退出。另外，还可以通过调用诸如thread.exit()之类的退出函数，或者sys.exit()之类的退出python进程的标准方法，
  异或抛出SystemExit异常，来使线程退出。但是，不能直接“终止”一个线程————主线程退出之后，所有其它线程都会在没有清理的情况下直接退出。
  模块threading会确保在所有“重要的”子线程退出前，保持整个进程的存活。
  
  python虽然支持多线程编程，但是还需要取决于它所运行的操作系统。如下操作系统时支持多线程的：绝大多数类UNIX平台，以及windows平台。python使用兼容
  POSIX的线程，也就是众所周知的pthread。
  
  python 提供了多个模块来支持多线程编程，包括_thread、threading、和queue模块等。
  _thread模块提供了基本的线程和锁定支持；而threading模块提供了更高级别、功能更加全面的线程管理。使用queue模块，
  用户可以创建一个队列数据结构，用于在多线程之间进行共享。
  
  推荐使用更高级别的threading模块而不是_thread模块有很多原因。threading模块更加先进，有更好的线程支持，并且_thread模块中的一些属性会和threading
  模块有冲突。另一个原因是低级别的_thread模块拥有的同步原语很少（实际上只有一个），而threading模块则有很多。
  
  避免使用_thread模块的另一个原因是它对于进程何时退出没有控制。当主线程结束时，所有其它线程也都强制结束，不会发出警告或者进行适当的清理。
  至少threading模块能确保重要的子线程在进程退出之前结束。
  我们只建议那些想访问线程的更底层级别的专家使用thread模块。为了强调这一点，在python3中该模块被重命名为_thread。
  
  除了派生线程以外，_thread模块还提供了基本的同步数据结构，称为锁对象（lock object， 也叫原语锁、简单锁、互斥锁、互斥和二进制信号量）。
  如前所述，这个同步原语和线程管理是密切相关的。
  
  _thread模块的核心函数是start_new_thread()。它的参数包括函数（对象）、函数的参数以及可选的关键字参数。将专门派生新的线程来调用这个函数。
  
  _thread模块和锁对象：
      _thread模块的函数：
          start_new_thread(function, args, kwargs=None)     派生一个新的线程，使用给定的args和可选的kwargs来执行function
          allocated_lock()                                  分配LockType锁对象
          exit()                                            给线程退出指令
      LockType锁对象的方法：
          acquire（wait=None）                              尝试获取锁对象
          locked（）                                        如果获取了锁对象则返回True，否则返回False
          release（）                                       释放锁
          
  start_new_thread() 必须包含开始的两个参数，于是即使要执行的函数不需要参数，也需要传递一个空元组。
  通过使用_thread.allocate_lock()函数得到锁对象，然后通过acquire()方法取得（每个锁）。取得锁效果相当于“把锁锁上”。
  一旦锁被锁上后，就可以把它添加到锁列表locks中。
  
  threading模块的对象：
      Thread          表示一个执行线程的对象
      Lock            锁原语对象（和thread模块的锁一样）
      RLock           可重入锁对象，是单一线程可以（再次）获得已持有的锁（递归锁）
      Condition       条件变量对象，使得一个线程等待另一个线程满足特定的“条件”，比如改变状态或某个数据值。
      Even            条件变量的通用版本，任意数量的线程等待某个事件的发生，在该事件发生后所有线程将被激活。
      Semaphore       为线程间共享的有限资源提供了一个计数器，如果没有可用资源时会被阻塞。
      BoundedSemaphore与Semaphore相似，不过它不允许超过初始值。
      Timer           与Thread相似，不过它要在运行前等待一段时间。
      Barrier         创建一个“障碍”，必须达到指定数量的线程才能继续
      
  避免使用_thead模块的另一个原因时该模块不支持守护线程这个概念，当主线程退出时，所有线程都将终止，不管他们是否仍在工作。如果你不希望发生这种行为，
  就要引入守护线程的概念了。
  threading模块支持守护线程，其工作方式是：守护线程一般是一个等待客户端请求的服务器。如果没有客户端请求，守护线程就是空闲的。
  如果把一个线程设置为守护线程，就表示这个线程是不重要的，进程退出时不需要等待这个线程执行完成。
  
  如果主线程准备退出时，不需要等待某些子线程完成，就可以为这些子线程设置守护线程标记。该标记值为真时，表示该线程是不重要的，或者说该线程只是用来
  等待客户端请求而不做任何事情。
  
  要将一个线程设置为守护线程，需要再启动线程之前执行如下赋值语句：threading.daemon = True（调用thread.setDaemon(True)的旧方法已经弃用了）。
  同样，要检查线程的守护状态，只需要检查这个值即可（对比过去调用thread.isDaemon()的方法）。一个新的子线程会继承父线程的守护标记。
  整个python程序（可以解读为：主线程）将在所有（注意！）非守护线程退出之后才退出。
  
  
  threading模块的Thread类是主要的执行对象。它有thread模块中没有的很多函数。
  
      class Thread(builtins.object)
     |  A class that represents a thread of control.
     |  
     |  This class can be safely subclassed in a limited fashion. There are two ways
     |  to specify the activity: by passing a callable object to the constructor, or
     |  by overriding the run() method in a subclass.
     |  
     |  Methods defined here:
     |  
     |  __init__(self, group=None, target=None, name=None, args=(), kwargs=None, *, daemon=None)
     |      This constructor should always be called with keyword arguments. Arguments are:
     |      
     |      *group* should be None; reserved for future extension when a ThreadGroup
     |      class is implemented.
     |      
     |      *target* is the callable object to be invoked by the run()
     |      method. Defaults to None, meaning nothing is called.
     |      
     |      *name* is the thread name. By default, a unique name is constructed of
     |      the form "Thread-N" where N is a small decimal number.
     |      
     |      *args* is the argument tuple for the target invocation. Defaults to ().
     |      
     |      *kwargs* is a dictionary of keyword arguments for the target
     |      invocation. Defaults to {}.
     |      
     |      If a subclass overrides the constructor, it must make sure to invoke
     |      the base class constructor (Thread.__init__()) before doing anything
     |      else to the thread.
     |  
     |  __repr__(self)
     |      Return repr(self).
     |  
     |  getName(self)
     |  
     |  isAlive = is_alive(self)
     |  
     |  isDaemon(self)
     |  
     |  is_alive(self)
     |      Return whether the thread is alive.
     |      
     |      This method returns True just before the run() method starts until just
     |      after the run() method terminates. The module function enumerate()
     |      returns a list of all alive threads.
     |  
     |  join(self, timeout=None)
     |      Wait until the thread terminates.
     |      
     |      This blocks the calling thread until the thread whose join() method is
     |      called terminates -- either normally or through an unhandled exception
     |      or until the optional timeout occurs.
     |      
     |      When the timeout argument is present and not None, it should be a
     |      floating point number specifying a timeout for the operation in seconds
     |      (or fractions thereof). As join() always returns None, you must call
     |      isAlive() after join() to decide whether a timeout happened -- if the
     |      thread is still alive, the join() call timed out.
     |      
     |      When the timeout argument is not present or None, the operation will
     |      block until the thread terminates.
     |      
     |      A thread can be join()ed many times.
     |      
     |      join() raises a RuntimeError if an attempt is made to join the current
     |      thread as that would cause a deadlock. It is also an error to join() a
     |      thread before it has been started and attempts to do so raises the same
     |      exception.
     |  
     |  run(self)
     |      Method representing the thread's activity.
     |      
     |      You may override this method in a subclass. The standard run() method
     |      invokes the callable object passed to the object's constructor as the
     |      target argument, if any, with sequential and keyword arguments taken
     |      from the args and kwargs arguments, respectively.
     |  
     |  setDaemon(self, daemonic)
     |  
     |  setName(self, name)
     |  
     |  start(self)
     |      Start the thread's activity.
     |      
     |      It must be called at most once per thread object. It arranges for the
     |      object's run() method to be invoked in a separate thread of control.
     |      
     |      This method will raise a RuntimeError if called more than once on the
     |      same thread object.
     |  
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |  
     |  __dict__
     |      dictionary for instance variables (if defined)
     |  
     |  __weakref__
     |      list of weak references to the object (if defined)
     |  
     |  daemon
     |      A boolean value indicating whether this thread is a daemon thread.
     |      
     |      This must be set before start() is called, otherwise RuntimeError is
     |      raised. Its initial value is inherited from the creating thread; the
     |      main thread is not a daemon thread and therefore all threads created in
     |      the main thread default to daemon = False.
     |      
     |      The entire Python program exits when no alive non-daemon threads are
     |      left.
     |  
     |  ident
     |      Thread identifier of this thread or None if it has not been started.
     |      
     |      This is a nonzero integer. See the thread.get_ident() function. Thread
     |      identifiers may be recycled when a thread exits and another thread is
     |      created. The identifier is available even after the thread has exited.
     |  
     |  name
     |      A string used for identification purposes only.
     |      
     |      It has no semantics. Multiple threads may be given the same name. The
     |      initial name is set by the constructor.
    
           
           
           
    使用Thread类创建多线程的几个推荐方法有：
            创建Thread的实例，传给它一个函数
            创建Thread的实例，传给它一个可调用的类实例
            创建Thread的子类，并创建子类的实例
            
    
    
    当实例化每个Thread对象时，把函数就（target）和参数（args）传进去，然后得到返回的Thread实例。实例化Thread（调用Thread()）和
    调用thread.start_new_thread()的最大区别是新线程不会立即开始执行。这是一个非常有用的同步功能，尤其是当你并不希望线程立即开始执行时。
    
    当所有线程都分配完成之后，通过调用每个线程的start()方法让它们开始执行，而不是在这之前就会执行。相比于管理一组锁（分配、获取、释放、
    检查锁状态等）而言，这里只需要为每个线程调用join()方法即可。join()方法将等待线程结束，或者在提供了超时时间的情况下，达到超时时间。
    使用join()方法要比等待锁释放的无限循环更加清晰（这也是这种锁又称为自旋锁的原因）
    
    对于join()方法而言，起另一个重要方面是其实他根本不需要调用。一单线程启动，他们就会一直执行，直到给定的函数完成后退出。
    如果主线程还有其他事情要去做，而不是等待这些线程完成（例如其它处理或者等新的客户端请求），就可以不用嗲用join()。join()方法只有在
    需要等待线程完成的时候才是有用的。
    
    
    
    threading模块的函数
    
    FUNCTIONS
    Lock = allocate_lock(...)
        allocate_lock() -> lock object
        (allocate() is an obsolete synonym)
        
        Create a new lock object. See help(type(threading.Lock())) for
        information about locks.
    
    RLock(*args, **kwargs)
        Factory function that returns a new reentrant lock.
        
        A reentrant lock must be released by the thread that acquired it. Once a
        thread has acquired a reentrant lock, the same thread may acquire it again
        without blocking; the thread must release it once for each time it has
        acquired it.
    
    active_count()
        Return the number of Thread objects currently alive.
        
        The returned count is equal to the length of the list returned by
        enumerate().
    
    current_thread()
        Return the current Thread object, corresponding to the caller's thread of control.
        
        If the caller's thread of control was not created through the threading
        module, a dummy thread object with limited functionality is returned.
    
    enumerate()
        Return a list of all Thread objects currently alive.
        
        The list includes daemonic threads, dummy thread objects created by
        current_thread(), and the main thread. It excludes terminated threads and
        threads that have not yet been started.
    
    get_ident(...)
        get_ident() -> integer
        
        Return a non-zero integer that uniquely identifies the current thread
        amongst other threads that exist simultaneously.
        This may be used to identify per-thread resources.
        Even though on some platforms threads identities may appear to be
        allocated consecutive numbers starting at 1, this behavior should not
        be relied upon, and the number should be seen purely as a magic cookie.
        A thread's identity may be reused for another thread after it exits.
    
    main_thread()
        Return the main thread object.
        
        In normal conditions, the main thread is the thread from which the
        Python interpreter was started.
    
    setprofile(func)
        Set a profile function for all threads started from the threading module.
        
        The func will be passed to sys.setprofile() for each thread, before its
        run() method is called.
    
    settrace(func)
        Set a trace function for all threads started from the threading module.
        
        The func will be passed to sys.settrace() for each thread, before its run()
        method is called.
    
    stack_size(...)
        stack_size([size]) -> size
        
        Return the thread stack size used when creating new threads.  The
        optional size argument specifies the stack size (in bytes) to be used
        for subsequently created threads, and must be 0 (use platform or
        configured default) or a positive integer value of at least 32,768 (32k).
        If changing the thread stack size is unsupported, a ThreadError
        exception is raised.  If the specified size is invalid, a ValueError
        exception is raised, and the stack size is unmodified.  32k bytes
         currently the minimum supported stack size value to guarantee
        sufficient stack space for the interpreter itself.
        
        Note that some platforms may have particular restrictions on values for
        the stack size, such as requiring a minimum stack size larger than 32kB or
        requiring allocation in multiples of the system memory page size
        - platform documentation should be referred to for more information
        (4kB pages are common; using multiples of 4096 for the stack size is
        the suggested approach in the absence of more specific information).
    
    
    
    多线程编程中一个非常重要的方面：同步。
    一般在多线程代码中，总会有加一些特定的函数或代码块不希望（或不应该）被多个线程同时执行，通常包括修改数据库、更新文件或其它会产生竞态条件的
    类似情况。如果过两个线程运行的顺序发生变化，就有可能造成代码的执行轨迹或行为不相同，或者产生不一致的数据（可以在Wikipedia页面上阅读有关竞态
    条件的更多信息）
    
    这就是需要使用同步的情况。当任意数量的线程可以访问临界区的代码，但在给定的时刻只有一个线程可以通过时，就是使用同步的时候了。程序员选择适合的
    同步原语，或者线程控制只来执行同步。进程同步有不同的类型。
    锁是所有机制中最简单、最低级的机制，而信号量用于多线程竞争有限资源的情况。
    
    锁有两种状态：锁定和未锁定。而且它也只支持两个函数： 获得锁和释放锁。
    当多线程争夺锁时，允许第一个获得锁的线程进入临界区，并执行代码。所有之后到达的线程将被阻塞，直到第一个线程执行结束，退出临界区，并释放锁。
    此时，其他等待的线程可以获得锁并进入临界区。但是，那些被阻塞的线程没有顺序的，胜出线程的选择是不确定的，而且还会根据python实现的不同而有所区别。
    
    多个线程可能并行执行I/O，输出可能部分混乱。另一个问题是在两个线程修改同一个变量（剩余线程名集合）时。
    I/O和访问相同的数据结构都属于临界区，因此需要用锁来防止多个线程同时进入临界区。为了加锁，需要添加一行代码来引入Lock（或LRLock），
    然后创建一个锁对象。
    
    作为维护你自己的当前运行线程集合的一种替代方案，可以考虑使用threading.enumerate()，该方法会返回仍在运行的线程列表（包括守护线程，
    当前线程，以及主线程，但不包括没有启动的线程）。
    还可以使用str.format()方法来替代字符串格式化操作符。
    
    
    
    还有一种方案可以不在调用锁的acquire()和release()方法，从而更进一步简化代码。这就是使用with语句，此时每个对象的上下文管理器负责在进入该
    套件之前调用acquire()并在完成执行之后调用release()。
    
    threading模块的对象Lock、RLock、Condition、Condition、Semaphore和BoundedSemphore都包含上下文管理器，也就是说，他们都可以使用with语句。
    
    信号量是最古老的同步原语之一。它是一个计数器，当资源消耗时递减，当资源释放时递增。资源消耗使计数器递减的操作习惯上称为P()，也称为wait、
    try、acquire、pend或procure。相对地，当一个线程对一个资源完成操作时，该资源需要返回资源池中。这个操作一般称为V()，也称为signal、increment、
    release、post、vacate。python简化了所有的命名，使用和锁的函数/方法一样的名字：acquire和release。信号量比锁更加灵活，因为可以有多个线程，
    每个线程拥有有限资源的一个实例。
    
    当分配一个单位的资源时，计数器值减 1，而当一个单位的资源返回资源池时，计数器值加 1。BoundedSemaphore的一个额外功能是这个计数器的值永远
    不会超过它的初始值，换句话说，他可以防范其中信号量释放次数多于获得次数的异常用例。
    
    通过传入非阻塞的标志Falses，让调用不再阻塞，而在应当阻塞的时候放回一个False，指明没有更多的资源了。
    
    threading模块的同步原语并不是类名，即便它们使用了驼峰式的拼写方法，看起来像是类名。实际上，他们是仅有一行的函数，用来实例化你认为的那个类的对象。
    这里有两个问题需要考虑：其一，你不能对他们子类化（因为它们是函数）；其二，变量名在2.x 和 3.x版本间发生了改变。
    计数器的值只是类的一个属性，所以可以直接访问它，这个变量名是self._value。
    对于开方则而言，最简洁的API是继承threading._BoundedSemaphore类，并实现一个__len__()方法，不过要注意，如果你计划对2.x和3.x版本都支持，
    还是需要使用刚才讨论过的那个正确的计数值。
    
    我们使用queue模块来提供线程间的通信机制，从而让线程之间可以互相分享数据。
    
    NAME
    queue - A multi-producer, multi-consumer queue.

CLASSES
    builtins.Exception(builtins.BaseException)
        Empty
        Full
    builtins.object
        Queue
            LifoQueue
            PriorityQueue
    
    class Empty(builtins.Exception)
     |  Exception raised by Queue.get(block=0)/get_nowait().
     |  
     |  Method resolution order:
     |      Empty
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |  
     |  Data descriptors defined here:
     |  
     |  __weakref__
     |      list of weak references to the object (if defined)
     |  
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.Exception:
     |  
     |  __init__(self, /, *args, **kwargs)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |  
     |  __new__(*args, **kwargs) from builtins.type
     |      Create and return a new object.  See help(type) for accurate signature.
     |  
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |  
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |  
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |  
     |  __reduce__(...)
     |      helper for pickle
     |  
     |  __repr__(self, /)
     |      Return repr(self).
     |  
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |  
     |  __setstate__(...)
     |  
     |  __str__(self, /)
     |      Return str(self).
     |  
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |  
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |  
     |  __cause__
     |      exception cause
     |  
     |  __context__
     |      exception context
     |  
     |  __dict__
     |  
     |  __suppress_context__
     |  
     |  __traceback__
     |  
     |  args
    
    class Full(builtins.Exception)
     |  Exception raised by Queue.put(block=0)/put_nowait().
     |  
     |  Method resolution order:
     |      Full
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |  
     |  Data descriptors defined here:
     |  
     |  __weakref__
     |      list of weak references to the object (if defined)
     |  
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.Exception:
     |  
     |  __init__(self, /, *args, **kwargs)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |  
     |  __new__(*args, **kwargs) from builtins.type
     |      Create and return a new object.  See help(type) for accurate signature.
     |  
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |  
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |  
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |  
     |  __reduce__(...)
     |      helper for pickle
     |  
     |  __repr__(self, /)
     |      Return repr(self).
     |  
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |  
     |  __setstate__(...)
     |  
     |  __str__(self, /)
     |      Return str(self).
     |  
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |  
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |  
     |  __cause__
     |      exception cause
     |  
     |  __context__
     |      exception context
     |  
     |  __dict__
     |  
     |  __suppress_context__
     |  
     |  __traceback__
     |  
     |  args
    
    class LifoQueue(Queue)
     |  Variant of Queue that retrieves most recently added entries first.
     |  
     |  Method resolution order:
     |      LifoQueue
     |      Queue
     |      builtins.object
     |  
     |  Methods inherited from Queue:
     |  
     |  __init__(self, maxsize=0)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |  
     |  empty(self)
     |      Return True if the queue is empty, False otherwise (not reliable!).
     |      
     |      This method is likely to be removed at some point.  Use qsize() == 0
     |      as a direct substitute, but be aware that either approach risks a race
     |      condition where a queue can grow before the result of empty() or
     |      qsize() can be used.
     |      
     |      To create code that needs to wait for all queued tasks to be
     |      completed, the preferred technique is to use the join() method.
     |  
     |  full(self)
     |      Return True if the queue is full, False otherwise (not reliable!).
     |      
     |      This method is likely to be removed at some point.  Use qsize() >= n
     |      as a direct substitute, but be aware that either approach risks a race
     |      condition where a queue can shrink before the result of full() or
     |      qsize() can be used.
     |  
     |  get(self, block=True, timeout=None)
     |      Remove and return an item from the queue.
     |      
     |      If optional args 'block' is true and 'timeout' is None (the default),
     |      block if necessary until an item is available. If 'timeout' is
     |      a non-negative number, it blocks at most 'timeout' seconds and raises
     |      the Empty exception if no item was available within that time.
     |      Otherwise ('block' is false), return an item if one is immediately
     |      available, else raise the Empty exception ('timeout' is ignored
     |      in that case).
     |  
     |  get_nowait(self)
     |      Remove and return an item from the queue without blocking.
     |      
     |      Only get an item if one is immediately available. Otherwise
     |      raise the Empty exception.
     |  
     |  join(self)
     |      Blocks until all items in the Queue have been gotten and processed.
     |      
     |      The count of unfinished tasks goes up whenever an item is added to the
     |      queue. The count goes down whenever a consumer thread calls task_done()
     |      to indicate the item was retrieved and all work on it is complete.
     |      
     |      When the count of unfinished tasks drops to zero, join() unblocks.
     |  
     |  put(self, item, block=True, timeout=None)
     |      Put an item into the queue.
     |      
     |      If optional args 'block' is true and 'timeout' is None (the default),
     |      block if necessary until a free slot is available. If 'timeout' is
     |      a non-negative number, it blocks at most 'timeout' seconds and raises
     |      the Full exception if no free slot was available within that time.
     |      Otherwise ('block' is false), put an item on the queue if a free slot
     |      is immediately available, else raise the Full exception ('timeout'
     |      is ignored in that case).
     |  
     |  put_nowait(self, item)
     |      Put an item into the queue without blocking.
     |      
     |      Only enqueue the item if a free slot is immediately available.
     |      Otherwise raise the Full exception.
     |  
     |  qsize(self)
     |      Return the approximate size of the queue (not reliable!).
     |  
     |  task_done(self)
     |      Indicate that a formerly enqueued task is complete.
     |      
     |      Used by Queue consumer threads.  For each get() used to fetch a task,
     |      a subsequent call to task_done() tells the queue that the processing
     |      on the task is complete.
     |      
     |      If a join() is currently blocking, it will resume when all items
     |      have been processed (meaning that a task_done() call was received
     |      for every item that had been put() into the queue).
     |      
     |      Raises a ValueError if called more times than there were items
     |      placed in the queue.
     |  
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from Queue:
     |  
     |  __dict__
     |      dictionary for instance variables (if defined)
     |  
     |  __weakref__
     |      list of weak references to the object (if defined)
    
    class PriorityQueue(Queue)
     |  Variant of Queue that retrieves open entries in priority order (lowest first).
     |  
     |  Entries are typically tuples of the form:  (priority number, data).
     |  
     |  Method resolution order:
     |      PriorityQueue
     |      Queue
     |      builtins.object
     |  
     |  Methods inherited from Queue:
     |  
     |  __init__(self, maxsize=0)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |  
     |  empty(self)
     |      Return True if the queue is empty, False otherwise (not reliable!).
     |      
     |      This method is likely to be removed at some point.  Use qsize() == 0
     |      as a direct substitute, but be aware that either approach risks a race
     |      condition where a queue can grow before the result of empty() or
     |      qsize() can be used.
     |      
     |      To create code that needs to wait for all queued tasks to be
     |      completed, the preferred technique is to use the join() method.
     |  
     |  full(self)
     |      Return True if the queue is full, False otherwise (not reliable!).
     |      
     |      This method is likely to be removed at some point.  Use qsize() >= n
     |      as a direct substitute, but be aware that either approach risks a race
     |      condition where a queue can shrink before the result of full() or
     |      qsize() can be used.
     |  
     |  get(self, block=True, timeout=None)
     |      Remove and return an item from the queue.
     |      
     |      If optional args 'block' is true and 'timeout' is None (the default),
     |      block if necessary until an item is available. If 'timeout' is
     |      a non-negative number, it blocks at most 'timeout' seconds and raises
     |      the Empty exception if no item was available within that time.
     |      Otherwise ('block' is false), return an item if one is immediately
     |      available, else raise the Empty exception ('timeout' is ignored
     |      in that case).
     |  
     |  get_nowait(self)
     |      Remove and return an item from the queue without blocking.
     |      
     |      Only get an item if one is immediately available. Otherwise
     |      raise the Empty exception.
     |  
     |  join(self)
     |      Blocks until all items in the Queue have been gotten and processed.
     |      
     |      The count of unfinished tasks goes up whenever an item is added to the
     |      queue. The count goes down whenever a consumer thread calls task_done()
     |      to indicate the item was retrieved and all work on it is complete.
     |      
     |      When the count of unfinished tasks drops to zero, join() unblocks.
     |  
     |  put(self, item, block=True, timeout=None)
     |      Put an item into the queue.
     |      
     |      If optional args 'block' is true and 'timeout' is None (the default),
     |      block if necessary until a free slot is available. If 'timeout' is
     |      a non-negative number, it blocks at most 'timeout' seconds and raises
     |      the Full exception if no free slot was available within that time.
     |      Otherwise ('block' is false), put an item on the queue if a free slot
     |      is immediately available, else raise the Full exception ('timeout'
     |      is ignored in that case).
     |  
     |  put_nowait(self, item)
     |      Put an item into the queue without blocking.
     |      
     |      Only enqueue the item if a free slot is immediately available.
     |      Otherwise raise the Full exception.
     |  
     |  qsize(self)
     |      Return the approximate size of the queue (not reliable!).
     |  
     |  task_done(self)
     |      Indicate that a formerly enqueued task is complete.
     |      
     |      Used by Queue consumer threads.  For each get() used to fetch a task,
     |      a subsequent call to task_done() tells the queue that the processing
     |      on the task is complete.
     |      
     |      If a join() is currently blocking, it will resume when all items
     |      have been processed (meaning that a task_done() call was received
     |      for every item that had been put() into the queue).
     |      
     |      Raises a ValueError if called more times than there were items
     |      placed in the queue.
     |  
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from Queue:
     |  
     |  __dict__
     |      dictionary for instance variables (if defined)
     |  
     |  __weakref__
     |      list of weak references to the object (if defined)
    
    class Queue(builtins.object)
     |  Create a queue object with a given maximum size.
     |  
     |  If maxsize is <= 0, the queue size is infinite.
     |  
     |  Methods defined here:
     |  
     |  __init__(self, maxsize=0)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |  
     |  empty(self)
     |      Return True if the queue is empty, False otherwise (not reliable!).
     |      
     |      This method is likely to be removed at some point.  Use qsize() == 0
     |      as a direct substitute, but be aware that either approach risks a race
     |      condition where a queue can grow before the result of empty() or
     |      qsize() can be used.
     |      
     |      To create code that needs to wait for all queued tasks to be
     |      completed, the preferred technique is to use the join() method.
     |  
     |  full(self)
     |      Return True if the queue is full, False otherwise (not reliable!).
     |      
     |      This method is likely to be removed at some point.  Use qsize() >= n
     |      as a direct substitute, but be aware that either approach risks a race
     |      condition where a queue can shrink before the result of full() or
     |      qsize() can be used.
     |  
     |  get(self, block=True, timeout=None)
     |      Remove and return an item from the queue.
     |      
     |      If optional args 'block' is true and 'timeout' is None (the default),
     |      block if necessary until an item is available. If 'timeout' is
     |      a non-negative number, it blocks at most 'timeout' seconds and raises
     |      the Empty exception if no item was available within that time.
     |      Otherwise ('block' is false), return an item if one is immediately
     |      available, else raise the Empty exception ('timeout' is ignored
     |      in that case).
     |  
     |  get_nowait(self)
     |      Remove and return an item from the queue without blocking.
     |      
     |      Only get an item if one is immediately available. Otherwise
     |      raise the Empty exception.
     |  
     |  join(self)
     |      Blocks until all items in the Queue have been gotten and processed.
     |      
     |      The count of unfinished tasks goes up whenever an item is added to the
     |      queue. The count goes down whenever a consumer thread calls task_done()
     |      to indicate the item was retrieved and all work on it is complete.
     |      
     |      When the count of unfinished tasks drops to zero, join() unblocks.
     |  
     |  put(self, item, block=True, timeout=None)
     |      Put an item into the queue.
     |      
     |      If optional args 'block' is true and 'timeout' is None (the default),
     |      block if necessary until a free slot is available. If 'timeout' is
     |      a non-negative number, it blocks at most 'timeout' seconds and raises
     |      the Full exception if no free slot was available within that time.
     |      Otherwise ('block' is false), put an item on the queue if a free slot
     |      is immediately available, else raise the Full exception ('timeout'
     |      is ignored in that case).
     |  
     |  put_nowait(self, item)
     |      Put an item into the queue without blocking.
     |      
     |      Only enqueue the item if a free slot is immediately available.
     |      Otherwise raise the Full exception.
     |  
     |  qsize(self)
     |      Return the approximate size of the queue (not reliable!).
     |  
     |  task_done(self)
     |      Indicate that a formerly enqueued task is complete.
     |      
     |      Used by Queue consumer threads.  For each get() used to fetch a task,
     |      a subsequent call to task_done() tells the queue that the processing
     |      on the task is complete.
     |      
     |      If a join() is currently blocking, it will resume when all items
     |      have been processed (meaning that a task_done() call was received
     |      for every item that had been put() into the queue).
     |      
     |      Raises a ValueError if called more times than there were items
     |      placed in the queue.
     |  
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |  
     |  __dict__
     |      dictionary for instance variables (if defined)
     |  
     |  __weakref__
     |      list of weak references to the object (if defined)

DATA
    __all__ = ['Empty', 'Full', 'Queue', 'PriorityQueue', 'LifoQueue']
    
    
    
    线程的替代方案：
            subprocess模块：
                    这是派生进程的主要替代方案，可以单纯的执行任务，或者通过标准文件（stdin、stdout、stderr）进行进程间通信。
                    
            multiprocessing模块：
                    该模块允许为多核或多CPU派生进程，其接口与threading模块非常相似。该模块同样也包括在共享任务的进程间传输数据的多种方式。
            
            concurrent.futures模块：
                    这是一个新的高级库，它只在“任务”级别进行操作，你不再需要过分关注同步和线程/进程的管理。你只需要制定一个给定了“worker”
                    数量的线程/进程池，提交任务，然后整理结果。
                    
            
    
